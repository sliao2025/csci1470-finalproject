{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from scipy import interp\n",
    "import itertools\n",
    "from itertools import cycle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparams\n",
    "IMG_DIR = 'spectrogram_images/'\n",
    "IMG_HEIGHT = 216\n",
    "IMG_WIDTH = 216\n",
    "NUM_CLASSES = 7\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "L2_LAMBDA = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUR_DIR = os.getcwd()\n",
    "ROOT_DIR = os.path.dirname(CUR_DIR)\n",
    "SPECTO_DIR = os.path.join(ROOT_DIR, IMG_DIR)\n",
    "\n",
    "label_dict = {'Hip':0,\n",
    "              'Pop':1,\n",
    "              'Vocal':2,\n",
    "              'Rhythm':3,\n",
    "              'Reggae':4,\n",
    "              'Rock':5,\n",
    "              'Techno':6,\n",
    "             }\n",
    "\n",
    "one_hot = OneHotEncoder(categories=[range(NUM_CLASSES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Training and Validation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_history_path = 'fine_tuning_resnet152_pytorch_history.pkl'\n",
    "pkl_dir = os.path.join(ROOT_DIR, f'pickle_files/{train_val_history_path}')\n",
    "\n",
    "with open(pkl_dir, 'rb') as f:\n",
    "    scores = pickle.load(f)\n",
    "    \n",
    "print(scores.keys())\n",
    "scores = pd.DataFrame(scores, index=range(1,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(range(1,11))\n",
    "plt.plot(scores['train_loss'], marker='o', label='training_loss')\n",
    "plt.plot(scores['val_loss'], marker='d', label='validation_loss')\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.xlabel('Training Epochs', fontsize=12)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('plots/learning-curve-loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xticks(range(1,11))\n",
    "plt.plot(scores['train_accuracy'], marker='o', label='training_accuracy')\n",
    "plt.plot(scores['val_accuracy'], marker='d', label='validation_accuracy')\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.xlabel('Training Epochs', fontsize=12)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('plots/learning-curve-accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Best Model Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = models.resnet152(weights='DEFAULT')\n",
    "in_features = conv_base.fc.in_features\n",
    "conv_base.fc = torch.nn.Identity()\n",
    "\n",
    "test_model = nn.Sequential(\n",
    "  conv_base,\n",
    "  nn.Flatten(),\n",
    "  nn.Linear(in_features, 512),\n",
    "  nn.Dropout(p=0.3),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(512, NUM_CLASSES),\n",
    "  nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(ROOT_DIR, 'saved_models/fine_tuning_epoch_8_59.3413.pt')\n",
    "test_model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# unwrap if model saved with DataParallel\n",
    "if isinstance(test_model, nn.DataParallel):\n",
    "    test_model = test_model.module\n",
    "\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test files\n",
    "pkl_dir = os.path.join(ROOT_DIR, 'pickle_files/fine_tuning_resnet152_pytorch_test_files.pkl')\n",
    "with open(pkl_dir, 'rb') as f:\n",
    "  test_files = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, specto_dir, label_dict, IMG_WIDTH, IMG_HEIGHT):\n",
    "        self.files = files\n",
    "        self.specto_dir = specto_dir\n",
    "        self.label_dict = label_dict\n",
    "        self.one_hot = one_hot\n",
    "        self.IMG_WIDTH = IMG_WIDTH\n",
    "        self.IMG_HEIGHT = IMG_HEIGHT\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_ = self.files[idx]\n",
    "        im = Image.open(self.specto_dir + file_)\n",
    "        im = im.resize((self.IMG_WIDTH, self.IMG_HEIGHT), Image.Resampling.LANCZOS)\n",
    "        spectogram = np.array(im) / 255.0\n",
    "        \n",
    "        label = file_[:-4].split('_')\n",
    "        label_array = np.array([self.label_dict[label[1]]])\n",
    "        label_array = label_array.reshape(1, -1)\n",
    "        label_array = one_hot.fit_transform(label_array).toarray()\n",
    "\n",
    "        return spectogram, np.array(label_array[0])\n",
    "    \n",
    "# set training optimizer, loss, and metrics\n",
    "optimizer = optim.Adam(test_model.parameters(), lr=1e-5, weight_decay=L2_LAMBDA)\n",
    "loss_function = torch.nn.functional.cross_entropy\n",
    "\n",
    "def categorical_accuracy(output, target):\n",
    "    predicted = torch.argmax(output, dim=-1)\n",
    "    labels = torch.argmax(target, dim=-1)\n",
    "    correct = (predicted == labels).float()\n",
    "    return correct.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Prediction on Test set\n",
    "TEST_STEPS = len(test_files)//BATCH_SIZE\n",
    "\n",
    "test_dataset = CustomDataset(test_files, SPECTO_DIR, label_dict, IMG_WIDTH, IMG_HEIGHT)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "\n",
    "preds = np.empty((0,))\n",
    "pred_labels = np.empty((0,))\n",
    "pred_probs = np.empty((0,len(label_dict)))\n",
    "\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (inputs, targets) in tqdm(enumerate(test_loader), total=TEST_STEPS):\n",
    "    # Permute the inputs to [N, C, H, W] from [N, H, W, C]\n",
    "    inputs = inputs.permute(0, 3, 1, 2)\n",
    "    inputs = inputs.to(device, dtype=torch.float32)\n",
    "    targets = targets.to(device, dtype=torch.float32)\n",
    "    outputs = test_model(inputs)  # Forward pass\n",
    "    loss = loss_function(outputs, targets)  # Calculate the loss\n",
    "    test_loss += loss.item()\n",
    "    total_test += targets.size(0)\n",
    "    correct_test += categorical_accuracy(outputs, targets)\n",
    "\n",
    "    # for confusion matrix later\n",
    "    preds = np.concatenate((preds, torch.argmax(outputs, dim=-1).flatten()), axis=0)\n",
    "    pred_labels = np.concatenate((pred_labels, torch.argmax(targets, dim=-1).flatten()), axis=0)\n",
    "    # for ROC later\n",
    "    pred_probs = np.concatenate((pred_probs, outputs), axis=0)\n",
    "\n",
    "# Calculate average validation loss and accuracy\n",
    "avg_test_loss = test_loss / TEST_STEPS\n",
    "test_accuracy = 100. * correct_test / total_test\n",
    "\n",
    "# Print test metrics\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "print('Test Set F-score =  {0:.2f}'.format(f1_score(y_true=pred_labels[:len(preds)], y_pred=preds, average='macro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def one_hot_encoder(true_labels, num_records, num_classes):\n",
    "    temp = np.array(true_labels[:num_records])\n",
    "    true_labels = np.zeros((num_records, num_classes))\n",
    "    true_labels[np.arange(num_records), temp] = 1\n",
    "    return true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_true=pred_labels[:len(preds)], y_pred=preds), \n",
    "                      classes=label_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_true = one_hot_encoder(pred_labels, len(preds), len(label_dict))\n",
    "print('ROC AUC = {0:.3f}'.format(roc_auc_score(y_true=one_hot_true, y_score=pred_probs, average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute macro-average ROC curve and ROC area\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(NUM_CLASSES):\n",
    "    fpr[i], tpr[i], _ = roc_curve(one_hot_true[:, i], pred_probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])    \n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(NUM_CLASSES)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(NUM_CLASSES):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= NUM_CLASSES\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='Macro-average ROC curve (Area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
